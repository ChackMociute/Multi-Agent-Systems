{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa28be61-e17f-4e9b-a4e0-bf6cc65f88d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a7b106-677a-4abc-9167-6adbc1a18d48",
   "metadata": {},
   "source": [
    "# Fictitious play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca8382b-9967-4673-a46f-fd5e4ff20ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, actions, rewards, probs=None):\n",
    "        self.best_response = False\n",
    "        self.actions = self.create_actions(actions, probs)\n",
    "        self.rewards = rewards\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_actions(actions, probs):\n",
    "        if probs is None:\n",
    "            return {a: 1/len(actions) for a in actions}\n",
    "        if len(actions) != len(probs):\n",
    "            raise RuntimeError(\"Actions and probabilities should have the same length\")\n",
    "        if sum(probs) != 1:\n",
    "            raise ValueError(\"Probabilities should add up to 1\")\n",
    "        return {a: p for a, p in zip(actions, probs)}\n",
    "    \n",
    "    def set_opp_count(self):\n",
    "        self.opp_count = {a: 0 for a in self.rewards[self.select_action()].keys()}\n",
    "        \n",
    "    def record_opponent_action(self, opp_action):\n",
    "        if opp_action not in self.opp_count.keys():\n",
    "            raise KeyError(\"Opponent action different from the list of possible actions\")\n",
    "        self.opp_count[opp_action] += 1\n",
    "    \n",
    "    def select_action(self):\n",
    "        if self.best_response:\n",
    "            return self.select_best_response()\n",
    "        return choices(list(self.actions.keys()), weights=self.actions.values())[0]\n",
    "    \n",
    "    def select_best_response(self):\n",
    "        s = sum(self.opp_count.values())\n",
    "        utilities = {a: sum([self.rewards[a][a2] * c / s for a2, c in self.opp_count.items()])\n",
    "                     for a in self.actions.keys()}\n",
    "        return max(utilities, key=utilities.get)\n",
    "\n",
    "\n",
    "class Game:\n",
    "    def __init__(self, agents, n_initial_games=1, total_games=10000):\n",
    "        self.n_initial_games = n_initial_games\n",
    "        self.total_games = total_games\n",
    "        self.agents = agents\n",
    "    \n",
    "    def play_game(self):\n",
    "        a1, a2 = self.agents\n",
    "        a1.record_opponent_action(a2.select_action())\n",
    "        a2.record_opponent_action(a1.select_action())\n",
    "    \n",
    "    def play(self):\n",
    "        for agent in self.agents:\n",
    "            agent.set_opp_count()\n",
    "            agent.best_response = False\n",
    "        # Play some initial games randomly to accrue some data\n",
    "        for _ in range(self.n_initial_games):\n",
    "            self.play_game()\n",
    "        # Switch to playing best responses\n",
    "        for agent in self.agents:\n",
    "            agent.best_response = True\n",
    "        for _ in range(self.total_games - self.n_initial_games):\n",
    "            self.play_game()\n",
    "    \n",
    "    def summary(self):\n",
    "        print(f\"Player 1 plays the actions {tuple(game.agents[1].opp_count.keys())} with probabilities \" +\\\n",
    "              f\"{tuple(round(c / self.total_games, 3) for c in game.agents[1].opp_count.values())}\")\n",
    "        print(f\"Player 2 plays the actions {tuple(game.agents[0].opp_count.keys())} with probabilities \" +\\\n",
    "              f\"{tuple(round(c / self.total_games, 3) for c in game.agents[0].opp_count.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94938b-f4dc-4ebd-ba82-fcabe6a2fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1, A2 = ['A', 'B', 'C'], ['W', 'X', 'Y', 'Z']\n",
    "rewards = np.asarray([\n",
    "    [[1,5], [2,2], [3,4], [3,1]],\n",
    "    [[3,0], [4,1], [2,5], [4,2]],\n",
    "    [[1,3], [2,6], [5,2], [2,3]]\n",
    "])\n",
    "R1 = {a1: {a2: r[0] for a2, r in zip(A2, R)} for a1, R in zip(A1, rewards)}\n",
    "R2 = {a1: {a2: r[1] for a2, r in zip(A1, R)} for a1, R in zip(A2, rewards.swapaxes(0, 1))}\n",
    "game = Game([Agent(A1, R1), Agent(A2, R2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdb96bf-43f4-4699-9422-5b087e85ac9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1 plays the actions ('A', 'B', 'C') with probabilities (0.0, 0.5, 0.5)\n",
      "Player 2 plays the actions ('W', 'X', 'Y', 'Z') with probabilities (0.0, 0.6, 0.4, 0.0)\n"
     ]
    }
   ],
   "source": [
    "game.play()\n",
    "game.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb869a9-1957-4129-be7b-b3fe4e324426",
   "metadata": {},
   "source": [
    "# Monte Carlo sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11b71f52-a221-4834-bd7f-e2cc2d025144",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.568, 0.347\n"
     ]
    }
   ],
   "source": [
    "sample = np.cos(np.random.randn(1000000))**2\n",
    "print(f\"{sample.mean():.3}, {sample.std():.3}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
